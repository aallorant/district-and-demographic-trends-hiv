####################################################################################################
## Author: Adrien Allorant
##
## Description:
##    This script loads previously aggregated survey data, merges it with sector and geographic info,
##    then fits logistic hierarchical models (using INLA) for HIV indicators. Spatial adjacency matrices
##    are created for modeled regions, and results are saved for further analysis.
##
## Requirements:
##    - R version >= 4.0.0
##    - Packages: data.table, dplyr, stringr, tidyverse, INLA, countrycode,
##                sf, haven, PNWColors, R.utils
##
## Inputs:
##    - Prepped data files generated by previous scripts (".rdata").
##    - sector key file (sector_key.rds)
##    - geometry file (areas.geojson)
##
## Outputs:
##    - Model fits and results saved as .rds and .csv files in the designated output directories.
##    - Adjacency matrices for specified regions and indicators.
##
## Notes:
##    - Adjust directory paths and environment detection as needed.
##    - This script references a custom function `fit_logistic.R` that must be sourced beforehand.
##
####################################################################################################

# Clear environment (optional; not always best practice in scripts)
# rm(list=ls())

#####################################
## 00: Load Packages and Setup     ##
#####################################
library(data.table)
library(dplyr)
library(stringr)
library(tidyverse)
library(INLA)
library(countrycode)
library(sf)
library(haven)
library(PNWColors)
library(R.utils)

# Optional: ensure INLA is up-to-date
# inla.update()

#####################################
## 01: Determine Environment and Paths
#####################################

## Define root directory and relative paths
## Adjust these paths to match your repository structure.
if (run_rstudio) {
  # Example: using a local directory structure
  root <- "."  # or set this to your project root using here::here()
} else {
  args <- commandArgs(trailingOnly = TRUE)
  root <- args[1]
  indicator <- args[3]
}
post_proc_dir <- file.path(main_dir, 'prepped_data')
loc_areas_dir <- file.path(main_dir, 'geography_data')
out_dir       <- file.path(main_dir, 'output')
fig_dir       <- file.path(main_dir, 'figures')

# Create output directories if they don't exist
if(!dir.exists(out_dir)) dir.create(out_dir)
if(!dir.exists(fig_dir)) dir.create(fig_dir)

# Define color palette
pal <- rev(pnw_palette("Sailboat", 35))

#####################################
## 02: Define Indicators and Functions
#####################################

indicators <- c('hivstatus','test12m','arv')

# Source the logistic model fitting function (must exist in the main_dir)
source(file.path(main_dir, 'fit_logistic.R'))

# Tag for identifying model runs by date
tag <- Sys.Date()

#####################################
## 03: Example: Fit Models for One Indicator
#####################################

# In the original code, there is a loop over indicators and regions. 
# Below we show one example run for `arv`. Adapt as needed.

indicator <- 'arv'
cat('Fitting models for indicator: ', indicator, '\n')

# Load aggregated data for the chosen indicator
load(file.path(post_proc_dir, paste0(indicator, ".rdata")))

# Load sector data
sector <- readRDS(file.path(main_dir,'sector_key.rds'))
sector$iso3 <- countrycode(sector$country, "country.name", "iso3c")
# Add Botswana to Southern Africa sector
sector <- rbind(sector, data.frame(sector = 'Southern Africa', country = 'Botswana', iso3 = 'BWA'))

#####################################
## 04: Data Pre-processing
#####################################

data_aggregated <- data_aggregated %>%
  # Adjust SAB to ZAF
  mutate(iso3 = ifelse(iso3 == 'SAB', 'ZAF', iso3),
         year = as.numeric(str_extract(survey_id, '[0-9]+')),
         period = case_when(
           year < 2008 ~ 1,
           year < 2013 ~ 2,
           year < 2018 ~ 3,
           TRUE ~ 4
         )) %>%
  left_join(sector, by = "iso3")

# Load area information
area_merged <- setDT(read_sf(file.path(loc_areas_dir,"areas.geojson")))

# Special handling for Madagascar (MDG)
if('MDG' %in% unique(data_aggregated$iso3)){
  area_merged <- area_merged %>%
    bind_rows(
      setDT(read_sf(file.path(loc_areas_dir,"gadm41_MDG_shp/gadm41_MDG_2.shp"))) %>%
        dplyr::select(NAME_2, geometry) %>%
        mutate(iso3 = 'MDG', area_level = 2, 
               area_name = tolower(NAME_2),
               geoloc_area_id = paste0(iso3, '_2_', match(area_name, unique(area_name))),
               area_id = geoloc_area_id) %>%
        dplyr::select(-NAME_2)
    )
}

# Extract area_level from geoloc_area_id
data_aggregated <- data_aggregated %>%
  mutate(area_level = as.numeric(sub(".*_([0-9]+)_.*", "\\1", geoloc_area_id)),
         area_level = ifelse(is.na(area_level), 1, area_level))

# Identify the lowest area_level available per country
lowest_area_level <- data_aggregated %>%
  group_by(iso3) %>%
  summarize(lowest_area_level = min(area_level))

# Filter areas to keep only rows at the lowest area level per country
areas_filtered <- area_merged %>%
  inner_join(lowest_area_level, by = c("iso3", "area_level" = "lowest_area_level")) %>%
  bind_rows(
    area_merged %>%
      right_join(
        data_aggregated %>% filter(iso3 == 'CIV' & geoloc_area_id != 'CIV') %>%
          dplyr::select(iso3, geoloc_area_id) %>% distinct(),
        by = c("iso3","area_id" = "geoloc_area_id")
      )
  ) %>%
  arrange(area_sort_order) %>%
  mutate(area_idx = row_number())

# Clean geometry
areas_clean <- st_make_valid(st_as_sf(areas_filtered))
areas_clean <- st_simplify(areas_clean, preserveTopology = TRUE)

# Check geometry validity
if(!all(st_is_valid(areas_clean))){
  stop("Some geometries are still invalid.")
}

# Create adjacency matrix
adjM <- spdep::poly2nb(areas_clean)
adjM <- spdep::nb2mat(adjM, style = "B", zero.policy = TRUE)
colnames(adjM) <- rownames(adjM)

#####################################
## 05: Filter Data by Region and Sex for Modeling
#####################################

region <- 'Eastern Africa'
cat('Fitting models for region:', region, '\n')

# For ARV in Eastern Africa, exclude Ethiopia (as per original code comment)
if(region == 'Eastern Africa' & indicator == 'arv'){
  dt <- data_aggregated %>%
    filter(sector == region & country != 'Ethiopia')
} else {
  dt <- data_aggregated %>% filter(sector == region)
}

# Create output directories for region and sex
if(!dir.exists(file.path(out_dir, region))) dir.create(file.path(out_dir, region))

sex. <- 1 # Example: sex = 1 (Men), sex = 2 (Women)
sex_label <- c('Men', 'Women')[sex.]
cat('Fitting models for sex:', sex_label, '\n')

if(!dir.exists(file.path(out_dir, region, sex_label))) 
  dir.create(file.path(out_dir, region, sex_label))
tmp_dir <- file.path(out_dir, region, sex_label)

# Filter data by sex and convert Y, N to numeric
dt_s <- dt %>%
  filter(sex == sex.) %>%
  mutate(Y = round(as.numeric(zap_labels(Y))),
         N = round(as.numeric(zap_labels(N))))

#####################################
## 06: Create Index Maps for Categorical Variables
#####################################

iso3_map <- unique(dt_s$iso3)
area_map <- unique(dt_s$geoloc_area_id)
age_map <- sort(unique(dt_s$age_start))
res_map <- unique(dt_s$res_type)
edu_map <- sort(unique(dt_s$edu))
wealthq_map <- sort(unique(dt_s$wealthq_adj))
sur_map <- unique(dt_s$survey_id)
year_map <- unique(dt_s$year)
period_map <- sort(unique(dt_s$period))

# Add index variables to dt_s
dt_s <- dt_s %>%
  mutate(
    iso3_idx = match(iso3, iso3_map),
    area_idx = match(geoloc_area_id, area_map),
    age_idx = match(age_start, age_map),
    res_idx = match(res_type, res_map),
    edu_idx = match(edu, edu_map),
    wealthq_idx = match(wealthq_adj, wealthq_map),
    period_idx = match(period, period_map)
  )

#####################################
## 07: Create a Prediction Scaffold
#####################################

df <- crossing(
  period_idx = unique(dt_s$period_idx),
  sex = unique(dt_s$sex),
  res_idx = unique(dt_s$res_idx),
  wealthq_idx = unique(dt_s$wealthq_idx),
  edu_idx = unique(dt_s$edu_idx),
  age_idx = unique(dt_s$age_idx),
  areas_clean %>% 
    st_drop_geometry() %>%
    dplyr::select(iso3, area_id, area_name, area_level, area_sort_order, center_x, center_y) %>%
    filter(iso3 %in% unique(dt_s$iso3))
)

# Merge observations
df <- df %>%
  left_join(
    dt_s %>% dplyr::select(
      area_id = geoloc_area_id, survey_id, age_idx,
      sex, edu_idx, wealthq_idx, res_idx, period_idx,
      Y, N
    ),
    by = c("sex","res_idx","edu_idx","wealthq_idx","age_idx","area_id","period_idx")
  )

df$urban <- ifelse(df$res_idx == 1, 1, 0)

# Add iso3_idx and area_idx to df
df <- df %>%
  mutate(
    iso3_idx = match(iso3, iso3_map),
    area_idx = match(area_id, area_map)
  )

#####################################
## 08: Define Model Formulas
#####################################

# Baseline formula (example)
formula_baseline <- Y ~ 1 + 
  f(res_idx, constr = TRUE, hyper = list(prec = list(prior = "pc.prec", param = c(2.5, 0.01)))) +
  f(age_idx, model = "iid", constr = TRUE, hyper = list(prec = list(prior = "pc.prec", param = c(2.5, 0.01)))) +
  f(edu_idx, model = "iid", constr = TRUE, hyper = list(prec = list(prior = "pc.prec", param = c(2.5, 0.01)))) +
  f(wealthq_idx, model = "iid", constr = TRUE, hyper = list(prec = list(prior = "pc.prec", param = c(2.5, 0.01)))) +
  f(iso3_idx, model = "iid", constr = TRUE, hyper = list(prec = list(prior = "pc.prec", param = c(2.5, 0.01)))) +
  f(period_idx, model = "iid", constr = TRUE, hyper = list(prec = list(prior = "pc.prec", param = c(2.5, 0.01))))

# Additional model variants with interactions and spatial effects omitted for brevity.
# In original code, these are formula1 through formula5.
# Adjust as needed to replicate original models.

#####################################
## 09: Fit Models and Save Results
#####################################

# The original code loops through multiple formulas and models.
# Here we show the approach for all 5 models as in the original code.

formulas <- list(
  # formula1, formula2, formula3, formula4, formula5
  # Assign them as per original code.
)

models <- paste0("Model ", 1:5)

fit_results <- purrr::pmap(
  list(formula = formulas, model_name = models),
  ~ logistic_model(..1, ..2)  # logistic_model must be defined in fit_logistic.R
)

res_df <- lapply(fit_results, "[[", 1) %>% bind_rows()
res_fit <- lapply(fit_results, "[[", 2)

# Save fits and results
saveRDS(res_fit, file.path(tmp_dir, paste0(indicator, '-', tag, "-logit-sae-fits.rds")))
saveRDS(res_df, file.path(tmp_dir, paste0(indicator, '-', tag, "-logit-sae-df.rds")))

# Compute info criteria
ic_df <- sapply(res_fit, function(fit) {
  local_dic <- na.omit(fit$dic$local.dic)
  local_waic <- na.omit(fit$waic$local.waic)
  local_cpo <- na.omit(fit$cpo$cpo)
  
  c("dic" = sum(local_dic),
    "dic_se" = sd(local_dic)*sqrt(length(local_dic)),
    "waic" = sum(local_waic),
    "waic_se" = sd(local_waic)*sqrt(length(local_waic)),
    "cpo" = sum(local_cpo),
    "cpo_se" = sd(local_cpo)*sqrt(length(local_cpo)))
}) %>% t() %>% round() %>% as.data.frame() %>%
  mutate(model = unlist(models), .before = dic)

write_csv(ic_df, file.path(out_dir, paste0(indicator, '-information-criteria.csv')))

# Identify best model by cpo
best_model_index <- which.max(ic_df$cpo)
res_df_best <- filter(res_df, model == models[[best_model_index]])
res_fit_best <- res_fit[[best_model_index]]

write_csv(res_df_best, file.path(out_dir, paste0(indicator,'-best-logit-sae.csv')))
saveRDS(res_fit_best, file.path(out_dir, paste0(indicator,'-best-logit-sae-fit.rds')))

#####################################
## 10: Variance Decomposition (Optional)
#####################################
# Attempt to compute variance decomposition for random effects
variance_df <- tryCatch(
  {
    map(res_fit, function(fit) {
      fit$marginals.hyperpar %>%
        map_df(~ inla.emarginal(fun = function(y) 1 / y, .x)) %>%
        rename_all(~ str_replace(., "Precision for ", "Variance_"))
    }) %>%
      bind_rows() %>%
      select(starts_with("Variance")) %>%
      mutate(total_variance = rowSums(., na.rm = TRUE)) %>%
      mutate(across(starts_with("Variance"), ~ .x / total_variance, .names = "perc_{col}")) %>%
      mutate(model = unlist(models), .before = everything())
  },
  error = function(e) {
    message("Error computing variance decomposition: ", e$message)
    NULL
  }
)

if(!is.null(variance_df)) {
  write_csv(variance_df, file.path(tmp_dir, paste0(indicator,"-variance-proportions.csv")))
}


#####################################
## 11: Generating Adjacency Matrices for All Indicators and Regions
#####################################

# If needed, run a loop over indicators and regions to generate adjacency matrices
all_indicators <- c('hivstatus', 'test12m', 'arv')
regions <- c('Eastern Africa', 'Western Africa', 'Southern Africa', 'Central Africa')

for (indicator in all_indicators) {
  cat('Processing indicator:', indicator, '\n')
  
  # Load the indicator-specific data
  load(file.path(post_proc_dir, paste0(indicator, ".rdata")))
  
  # Add sector info
  sector <- readRDS(file.path(main_dir, 'sector_key.rds'))
  sector$iso3 <- countrycode(sector$country, "country.name", "iso3c")
  sector <- sector %>% rbind(data.frame(sector = 'Southern Africa', country = 'Botswana', iso3 = 'BWA'))
  
  data_aggregated <- data_aggregated %>%
    mutate(iso3 = ifelse(iso3 == 'SAB', 'ZAF', iso3),
           year = as.numeric(str_extract(survey_id, '[0-9]+')),
           period = case_when(
             year < 2008 ~ 1,
             year < 2013 ~ 2,
             year < 2018 ~ 3,
             TRUE ~ 4
           )) %>%
    left_join(sector, by = "iso3")
  
  # Load spatial geometry
  area_merged <- setDT(read_sf(file.path(loc_areas_dir,"areas.geojson")))
  
  for (region in regions) {
    cat('  Processing region:', region, '\n')
    
    region_data <- data_aggregated %>% filter(sector == region)
    
    if (nrow(region_data) == 0) {
      cat('  No data for region:', region, 'and indicator:', indicator, '\n')
      next
    }
    
    region_iso3 <- unique(region_data$iso3)
    area_filtered <- area_merged %>% filter(iso3 %in% region_iso3)
    
    areas_clean <- st_make_valid(st_as_sf(area_filtered))
    areas_clean <- st_simplify(areas_clean, preserveTopology = TRUE)
    
    if(!all(st_is_valid(areas_clean))){
      stop("Some geometries are still invalid after cleaning.")
    }
    
    adjM <- spdep::poly2nb(st_as_sf(areas_clean))
    adjM <- spdep::nb2mat(adjM, style = "B", zero.policy = TRUE)
    
    adjM_filename <- file.path(out_dir, paste0('adjM_', indicator, '_', str_replace_all(region, " ", "_"), '.rds'))
    saveRDS(adjM, adjM_filename)
    cat('  Saved adjacency matrix for indicator:', indicator, 'and region:', region, '\n')
  }
}